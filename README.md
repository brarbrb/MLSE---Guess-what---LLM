# ğŸ® Guess What â€” MLSE Project

## ğŸ‘©â€ğŸ’» Creators
Barbara Aleksandrov, Omer-Shay Becker & Kfir Nissim


## Overview
**Guess What** is an interactive multiplayer guessing game built using a microservices architecture (Flask&Sqlite and AI model (we used ollama)).  
Players describe and guess target word while avoiding "forbidden" words generated by the AI.  
The system combines **Flask + SocketIO** for real-time communication, **SQLite** for persistence, and a **custom LLM core** for intelligent word handling.

---

## ğŸ§© System Architecture
The project is organized into three main parts:

| Service | Description |
|----------|--------------|
| **web** | Flask backend serving APIs, SocketIO events, and frontend templates (HTML, JS, CSS). |
| **db** | SQLite database container for storing users, games, rounds, and chat messages. |
| **ai** | AI microservice (lm_core) responsible for generating target words, validating descriptions, and suggesting forbidden lists. |

---

## ğŸ› ï¸ Technologies
- **Python 3.11**
- **Flask** & **Flask-SocketIO**
- **SQLAlchemy**
- **SQLite**
- **Docker**
- **HTML / CSS / JavaScript**
- **LLM model** (`phi3:mini`)


--- 
## ğŸ“ Folder structure
```
project_root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # Flask entry point
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ db.py             # SQLAlchemy engine + session
â”‚   â”‚   â””â”€â”€ models.py         # ORM models
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ room_api.py       # Game logic routes
â”‚   â”œâ”€â”€ lm_core/      # AI logic
â”‚   â””â”€â”€ extensions.py   
|
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ templates/            # HTML files
â”‚   â”œâ”€â”€ static/               # CSS, JS, and assets
â”‚               
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ web/                #dockerfile for each service and requirements.txt
â”‚   â””â”€â”€ ai/ 
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ environment.yml          # for creating conda env
â””â”€â”€ README.md
```
---

## ğŸ‹ Setup and Run (Docker)
   ```bash
   git clone https://github.com/brarbrb/guess-what.git
   cd MLSE---Guess-what---LLM
   docker compose up --build
   ```
   (`docker compose down` to stop)
   
---
## âš™ï¸ Running Locaally (using conda)
We ensist on running only with conda (we installed miniconda3) if you don't want to suffer on cpu ğŸ™‚.

```bash
   git clone https://github.com/brarbrb/guess-what.git
   cd MLSE---Guess-what---LLM
   conda env create -f environment.yml
   conda activate guess-what
   python -m backend.main
```
